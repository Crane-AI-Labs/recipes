{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CprAi1X__k1q"
   },
   "source": [
    "# Unlock the Power of Swahili with Ganda Gemma 1B!\n",
    "\n",
    "Dive into the world of Swahili artificial intelligence with this comprehensive guide to using `CraneAILabs/swahili-gemma-1b`. As a fine-tuned version of Google's Gemma 3 1B model, Swahili Gemma is specially designed for English-to-Swahili translation and conversational AI. This notebook will walk you through everything you need to know, from the model's capabilities to hands-on-code examples.\n",
    "\n",
    "### **Model at a Glance**\n",
    "\n",
    "*   **Model Name:** `CraneAILabs/swahili-gemma-1b`\n",
    "*   **Base Model:** `google/gemma-3-1b-it`\n",
    "*   **Parameters:** 1 Billion\n",
    "*   **Input Languages:** English and Swahili\n",
    "*   **Output Language:** Swahili\n",
    "*   **Primary Focus:** English-to-Swahili translation and Swahili conversational AI\n",
    "\n",
    "### **Capabilities: What Can Swahili Gemma 1B Do?**\n",
    "\n",
    "This powerful model is equipped with a range of capabilities to serve various linguistic needs:\n",
    "\n",
    "*   **English-to-Swahili Translation:** Seamlessly translate text from English to Swahili.\n",
    "*   **Conversational AI:** Engage in natural, human-like conversations in Swahili.\n",
    "*   **Text Summarization:** Condense longer Swahili texts into concise summaries.\n",
    "*   **Creative and Informational Writing:** Generate a variety of written content in Swahili.\n",
    "*   **Question Answering:** Provide answers to general knowledge questions in Swahili.\n",
    "\n",
    "### **Performance that Speaks for Itself**\n",
    "\n",
    "Swahili Gemma 1B has been rigorously evaluated, demonstrating impressive performance in translation quality. Here's a look at how it stacks up against other models based on BLEU and chrF++ scores, evaluated on 1,012 translation samples:\n",
    "\n",
    "| Model | BLEU Score | chrF++ |\n",
    "| :--- | :--- | :--- |\n",
    "| Gemma 3 4B | 10.9 | 44.1 |\n",
    "| **Swahili Gemma 1B** | **27.6** | **56.8** |\n",
    "| Gemma 3 27B | 29.4 | 60.0 |\n",
    "| GPT-5 Mini | 31.8 | 62.4 |\n",
    "| Gemini 2.0 Flash | 35.6 | 64.6 |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6iyNh4BU_82i"
   },
   "source": [
    "\n",
    "## Let's Get Coding!\n",
    "\n",
    "### **Setup: Installing the Essentials**\n",
    "\n",
    "First, let's make sure you have the necessary libraries installed. We'll need `transformers` for interacting with the model and `torch` for the underlying computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "BmIpEmkUAAJY",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e9857aa5-93c0-4140-e7ab-734c98e561fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2B45fDysAEm9"
   },
   "source": [
    "### **Use Case 1: English-to-Swahili Translation**\n",
    "\n",
    "Translating from English to Swahili is a core feature of Swahili Gemma 1B. Hereâ€™s how you can do it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "a4734373175d4e66831f85faf5fb305d",
      "2f27e4e24174448bb3c4a9658cba8ae9",
      "032e54a306104006b76a45c53a8b314c",
      "5bfdc7d0fa2e4fb7ac8851bfccad007a",
      "4c812c5ed6064cfb903a1c8c3dd26cad",
      "31f914d490744337ac264127252acc2a",
      "2577091f2398431cb8fa3bb48c3c033c",
      "c16d7495f7a74acdaef4ed386262d8d0",
      "d02f4c3846604c34af270eae28db3405",
      "b4cf051c8f184fe3be3237818c9a17be",
      "ffd233c3f19b42c182c4ba632881b6b0",
      "0e22b5edf1714aff836c63358a42da9f",
      "e3b17c3a9395456082e1bc99e14423d0",
      "c86cce7d6f804a93a7e41d746370cd16",
      "9cb45b34c40e4bea8c717b5164760aed",
      "175accd533784604b0d83a9cf05adc9c",
      "680004ad9e1a4f05b529c93e5bd56203",
      "3837762560974112afea078f6021245f",
      "9ca17f35a50e43ce9363334f56c50c1f",
      "bfdc20d4ca6c438fbabb1618b2f3a308"
     ]
    },
    "id": "5TjxuDKAF8F4",
    "outputId": "5266eb15-bb41-447c-b833-ac67269b3970"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4734373175d4e66831f85faf5fb305d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8H6fkdvqALP2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"CraneAILabs/swahili-gemma-1b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pBaA8QoAPuM",
    "outputId": "452b8322-87ea-4c9d-f8f9-3704f84e44b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Response: user\n",
      "Translate to Swahili: Hello, how are you today?\n",
      "model\n",
      "Habari! Unaendeleaje leo?\n"
     ]
    }
   ],
   "source": [
    "# Create the chat-formatted prompt\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Translate to Swahili: Hello, how are you today?\"}\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate new tokens\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.3,\n",
    "        top_p=0.95,\n",
    "        top_k=64,\n",
    "        repetition_penalty=1.1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# The generated output will now contain both the formatted prompt and the answer.\n",
    "# We still need to decode and then extract just the model's response.\n",
    "full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Extract only the model's part of the response\n",
    "# Gemma's response starts after '<start_of_turn>model\\n'\n",
    "model_response = full_response.split('<start_of_turn>model\\n')[-1]\n",
    "\n",
    "print(f\"Model's Response: {model_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TauAgJrZAYJS",
    "outputId": "b0ec44d1-55cf-4888-8ca6-abfb25f86989"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pipeline Translation ---\n",
      "Generated Text: 'Karibuni shuleni'\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"CraneAILabs/swahili-gemma-1b\"\n",
    "\n",
    "# Load the tokenizer separately to build the prompt\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# --- Most Robust Pipeline for CPU ---\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=\"auto\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# 1. Apply the chat template just like before\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Translate to Swahili: Welcome to our school\"}\n",
    "]\n",
    "prompt_from_template = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# 2. Pass the formatted prompt to the generator\n",
    "result = generator(\n",
    "    prompt_from_template,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.3,\n",
    "    do_sample=True,\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- Pipeline Translation ---\")\n",
    "print(f\"Generated Text: '{result[0]['generated_text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWHIpfeTAdWj"
   },
   "source": [
    "### **Use Case 2: Swahili Conversational AI**\n",
    "\n",
    "Engage directly with the model in Swahili for a conversational experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUCzTC4jTvC7",
    "outputId": "c57af9ad-8630-4f01-ef5b-28242f02beca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat pipeline is ready. You can now start the conversation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"CraneAILabs/swahili-gemma-1b\"\n",
    "\n",
    "# Load the tokenizer separately. This is crucial for using the chat template.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create the text-generation pipeline with CPU optimizations\n",
    "# torch_dtype=\"auto\" helps torch select the right data type for your hardware (e.g., float32 for CPU)\n",
    "chat_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=\"auto\",\n",
    "    device=-1  # Use -1 to explicitly set to CPU\n",
    ")\n",
    "\n",
    "print(\"Chat pipeline is ready. You can now start the conversation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPtcIJqjTy99",
    "outputId": "c38bbab0-d5a9-4afb-bcf7-3d205b324527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Swahili Gemma Interactive Chat ---\n",
      "Model is ready. Type your message or a translation request.\n",
      "Type 'quit' or 'exit' to end the chat.\n",
      "\n",
      "You: habari\n",
      "Swahili Gemma: Habari! Naweza kukusaidia vipi leo?\n",
      "--------------------\n",
      "You: Tafadhali nieleze kwa maneno machache, dunia inakizunguka nini?\n",
      "Swahili Gemma: Wakati ulimwengu unaendelea kukua, tunakumbana na mabadiliko ya mara kwa mara, mabadiliko ya tabianchi, na matatizo ya kimazingira.\n",
      "--------------------\n",
      "You: hello\n",
      "Swahili Gemma: Habari! Naweza kukusaidia vipi leo?\n",
      "--------------------\n",
      "You: quit\n",
      "Goodbye! The chat session has ended.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Swahili Gemma Interactive Chat ---\")\n",
    "print(\"Model is ready. Type your message or a translation request.\")\n",
    "print(\"Type 'quit' or 'exit' to end the chat.\\n\")\n",
    "\n",
    "while True:\n",
    "    # 1. Get input from the user\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    # 2. Check for an exit command\n",
    "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "        print(\"Goodbye! The chat session has ended.\")\n",
    "        break\n",
    "\n",
    "    # 3. Format the input using the model's official chat template\n",
    "    # This is the most reliable way to get good responses from Gemma models.\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    prompt = chat_pipeline.tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # 4. Generate a response using the pipeline\n",
    "    # We use 'max_new_tokens' and 'return_full_text=False' to get a clean response.\n",
    "    response = chat_pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=150,\n",
    "        do_sample=True,\n",
    "        temperature=0.7, # A slightly higher temperature can make chat more interesting\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        return_full_text=False\n",
    "    )\n",
    "\n",
    "    # 5. Print the model's generated response\n",
    "    print(f\"Swahili Gemma: {response[0]['generated_text'].strip()}\")\n",
    "    print(\"-\" * 20) # Separator for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W83Bf8cI9DQP"
   },
   "source": [
    "***\n",
    "\n",
    "### **Use Case 4: Text Summarization in Swahili**\n",
    "\n",
    "Beyond translation, Swahili Gemma can understand and process Swahili text to extract the most important information. This is incredibly useful for condensing long articles, reports, or paragraphs into a short, easy-to-read summary.\n",
    "\n",
    "We'll use prompt engineering to instruct the model to act as a summarizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKgXzFPK9VId",
    "outputId": "3ad17089-b242-49cf-8026-287563a04db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Swahili Text Summarization ---\n",
      "Original Text:\n",
      "Wanafunzi walifika shuleni wakiwa wamechelewa, lakini mwalimu wao aliwapokea kwa furaha na kuwapa nafasi ya kujiunga na wenzao darasani ili wasipitwe na somo muhimu la hisabati ambalo lilikuwa likifundishwa.\n",
      "\n",
      "=========================\n",
      "\n",
      "Generated Summary:\n",
      "Wanafunzi walifika shuleni wakiwa wamechelewa, lakini walipokelewa na mwalimu wao kwa furaha na kupewa nafasi ya kujiunga na wanafunzi wenzao darasani.\n"
     ]
    }
   ],
   "source": [
    "# --- The Text to Summarize ---\n",
    "long_swahili_text = \"\"\"\n",
    "Wanafunzi walifika shuleni wakiwa wamechelewa, lakini mwalimu wao aliwapokea kwa furaha na kuwapa nafasi ya kujiunga na wenzao darasani ili wasipitwe na somo muhimu la hisabati ambalo lilikuwa likifundishwa.\"\"\"\n",
    "\n",
    "# --- The Instruction (Prompt) ---\n",
    "# We tell the model exactly what to do with the text.\n",
    "instruction = f\"Summarize the following Swahili text into one concise sentence: \\n\\n{long_swahili_text}\"\n",
    "\n",
    "# Format using the chat template for best results\n",
    "messages = [{\"role\": \"user\", \"content\": instruction}]\n",
    "prompt = chat_pipeline.tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Generate the summary\n",
    "# We use a low temperature for fact-based, non-creative output.\n",
    "summary_result = chat_pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.2, # Low temperature for factual summary\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "print(\"--- Swahili Text Summarization ---\")\n",
    "print(f\"Original Text:\\n{long_swahili_text.strip()}\")\n",
    "print(\"\\n\" + \"=\"*25 + \"\\n\")\n",
    "print(f\"Generated Summary:\\n{summary_result[0]['generated_text'].strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aGy4zTt9bOC"
   },
   "source": [
    "\n",
    "### **Use Case 5: Creative and Informational Writing**\n",
    "\n",
    "Need to write a short story, a poem, or an informational paragraph in Swahili? Swahili Gemma can be your creative partner. By providing a topic or a starting sentence, you can generate a variety of written content.\n",
    "\n",
    "For creative tasks, we'll increase the `temperature` parameter slightly to encourage the model to generate more diverse and interesting text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vW3ttCpn9sO2",
    "outputId": "34f27c20-bedd-42da-d3d3-79e1924b388c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creative Writing Example ---\n",
      "Prompt: Write a short story in Swahili about a bear and a friendly elephant.\n",
      "\n",
      "=========================\n",
      "\n",
      "Generated Story:\n",
      "Samahani, lakini siwezi kutafsiri maandishi hayo kwani hayako kwa lugha ya Kiingereza. Tafadhali nipe maandishi kwa Kiingereza ili niweze kukusaidia.\n"
     ]
    }
   ],
   "source": [
    "# --- Creative Writing: A Short Story ---\n",
    "story_idea = \"Write a short story in Swahili about a bear and a friendly elephant.\"\n",
    "\n",
    "messages_story = [{\"role\": \"user\", \"content\": story_idea}]\n",
    "prompt_story = chat_pipeline.tokenizer.apply_chat_template(\n",
    "    messages_story, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Use a higher temperature for more creative and unpredictable results\n",
    "creative_result = chat_pipeline(\n",
    "    prompt_story,\n",
    "    max_new_tokens=250, # Allow for a longer story\n",
    "    do_sample=True,\n",
    "    temperature=0.8, # Higher temperature for creativity\n",
    "    top_p=0.95,\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "print(\"--- Creative Writing Example ---\")\n",
    "print(f\"Prompt: {story_idea}\")\n",
    "print(\"\\n\" + \"=\"*25 + \"\\n\")\n",
    "print(f\"Generated Story:\\n{creative_result[0]['generated_text'].strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pDJuwJUCw70",
    "outputId": "75b21611-466b-47f5-d26b-37f331fdcc3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Informational Writing Example ---\n",
      "Prompt: Write a short paragraph in Swahili explaining the importance of boiling drinking water.\n",
      "\n",
      "=========================\n",
      "\n",
      "Generated Paragraph:\n",
      "Kunywa maji baridi ni muhimu sana kwa sababu inasaidia kuondoa bakteria na vijidudu ambavyo vinaweza kuambukiza mwili. Maji baridi husafisha mwili wetu na kuzuia magonjwa. Pia, maji baridi husaidia kuweka mwili wetu joto, na kuifanya iwe rahisi kwa mwili kutengeneza jasho. Kwa hivyo, kunywa maji baridi ni muhimu sana kwa afya yetu.\n"
     ]
    }
   ],
   "source": [
    "# --- Informational Writing: Factual Content ---\n",
    "info_idea = \"Write a short paragraph in Swahili explaining the importance of boiling drinking water.\"\n",
    "\n",
    "messages_info = [{\"role\": \"user\", \"content\": info_idea}]\n",
    "prompt_info = chat_pipeline.tokenizer.apply_chat_template(\n",
    "    messages_info, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Use a lower temperature for factual, informational text\n",
    "info_result = chat_pipeline(\n",
    "    prompt_info,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=True,\n",
    "    temperature=0.3, # Lower temperature for factual content\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "print(\"\\n\\n--- Informational Writing Example ---\")\n",
    "print(f\"Prompt: {info_idea}\")\n",
    "print(\"\\n\" + \"=\"*25 + \"\\n\")\n",
    "print(f\"Generated Paragraph:\\n{info_result[0]['generated_text'].strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O34ijpvw9zLr"
   },
   "source": [
    "### **Use Case 6: General Knowledge Question Answering**\n",
    "\n",
    "You can ask Swahili Gemma general knowledge questions directly in Swahili. The model will tap into the vast information it learned during its pre-training to provide an answer.\n",
    "\n",
    "This is another form of zero-shot learning. For the best factual recall, it's important to keep the `temperature` low to prevent the model from making things up (hallucinating).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NCF8qiS96bm",
    "outputId": "1d7483fd-83af-40c6-bb2f-5cb5739e90f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Question Answering Example ---\n",
      "Question: Mji mkuu wa Uganda ni nini?\n",
      "\n",
      "=========================\n",
      "\n",
      "Generated Answer: Mji mkuu wa Uganda ni Kampala.\n"
     ]
    }
   ],
   "source": [
    "# --- Ask a Question in Swahili ---\n",
    "question = \"Mji mkuu wa Uganda ni nini?\" # \"What is the capital city of Uganda?\"\n",
    "\n",
    "# Format the question using the chat template.\n",
    "messages_qa = [{\"role\": \"user\", \"content\": question}]\n",
    "prompt_qa = chat_pipeline.tokenizer.apply_chat_template(\n",
    "    messages_qa, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Generate the answer with a low temperature for accuracy.\n",
    "answer_result = chat_pipeline(\n",
    "    prompt_qa,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    temperature=0.1, # Very low temperature for factual answers\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "print(\"--- Question Answering Example ---\")\n",
    "print(f\"Question: {question}\")\n",
    "print(\"\\n\" + \"=\"*25 + \"\\n\")\n",
    "print(f\"Generated Answer: {answer_result[0]['generated_text'].strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sV87IcGg82jA",
    "outputId": "941f5713-0bc7-4ff8-dea1-b2b9fe403589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Another Question Answering Example ---\n",
      "Question: Kwa nini mazao yanahitaji maji ili kukua?\n",
      "\n",
      "=========================\n",
      "\n",
      "Generated Answer: Maji ni muhimu kwa ukuaji wa mazao. Husaidia kuweka maji kwenye mizizi ya mimea, ambayo ni muhimu kwa usambazaji wa virutubisho na oksijeni. Pia husaidia kudhibiti halijoto ya udongo na kuzuia ukuaji wa magugu.\n"
     ]
    }
   ],
   "source": [
    "# --- Another Example ---\n",
    "question_2 = \"Kwa nini mazao yanahitaji maji ili kukua?\" # \"Why do crops need water to grow?\"\n",
    "\n",
    "messages_qa_2 = [{\"role\": \"user\", \"content\": question_2}]\n",
    "prompt_qa_2 = chat_pipeline.tokenizer.apply_chat_template(\n",
    "    messages_qa_2, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "answer_result_2 = chat_pipeline(\n",
    "    prompt_qa_2,\n",
    "    max_new_tokens=150,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "print(\"\\n\\n--- Another Question Answering Example ---\")\n",
    "print(f\"Question: {question_2}\")\n",
    "print(\"\\n\" + \"=\"*25 + \"\\n\")\n",
    "print(f\"Generated Answer: {answer_result_2[0]['generated_text'].strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-fIwDDFAug1"
   },
   "source": [
    "### **Optimal Generation Parameters**\n",
    "\n",
    "To get the best results from Swahili Gemma 1B, it's recommended to use the following generation parameters:\n",
    "\n",
    "*   **`temperature`: 0.3** - For focused and coherent responses.\n",
    "*   **`top_p`: 0.95** - Utilizes nucleus sampling.\n",
    "*   **`top_k`: 64** - Employs top-k sampling.\n",
    "*   **`max_length`: 128** - Sets a limit on the response length.\n",
    "*   **`repetition_penalty`: 1.1** - Helps in reducing word repetition.\n",
    "*   **`do_sample`: True** - Enables sampling for more dynamic responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqy3qB98Azyx"
   },
   "source": [
    "### **Important Limitations to Consider**\n",
    "\n",
    "While Swahili Gemma 1B is a powerful tool, it's important to be aware of its limitations:\n",
    "\n",
    "*   **Swahili-Only Output:** The model is designed to respond exclusively in Swahili.\n",
    "*   **General Knowledge Base:** It has not been trained on specific factual datasets, so its knowledge is general.\n",
    "*   **No Coding or Math:** The model is not designed for programming or mathematical tasks.\n",
    "*   **Context Length:** For optimal performance, the context length is limited to 4,096 tokens.\n",
    "*   **Domain-Specific Fine-Tuning:** For specialized domains, further fine-tuning may be required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbxGVJSZA2vy"
   },
   "source": [
    "\n",
    "### **License Information**\n",
    "\n",
    "The Swahili Gemma 1B model is released under the Gemma Terms of Use. Please review the terms before using the model.\n",
    "\n",
    "We hope this notebook serves as an excellent starting point for your journey with Swahili AI. Happy coding"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "032e54a306104006b76a45c53a8b314c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_b4cf051c8f184fe3be3237818c9a17be",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ffd233c3f19b42c182c4ba632881b6b0",
      "value": ""
     }
    },
    "0e22b5edf1714aff836c63358a42da9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "175accd533784604b0d83a9cf05adc9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2577091f2398431cb8fa3bb48c3c033c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "2f27e4e24174448bb3c4a9658cba8ae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c16d7495f7a74acdaef4ed386262d8d0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d02f4c3846604c34af270eae28db3405",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "31f914d490744337ac264127252acc2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_175accd533784604b0d83a9cf05adc9c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_680004ad9e1a4f05b529c93e5bd56203",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "3837762560974112afea078f6021245f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ca17f35a50e43ce9363334f56c50c1f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bfdc20d4ca6c438fbabb1618b2f3a308",
      "value": "Connecting..."
     }
    },
    "4c812c5ed6064cfb903a1c8c3dd26cad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_c86cce7d6f804a93a7e41d746370cd16",
      "style": "IPY_MODEL_9cb45b34c40e4bea8c717b5164760aed",
      "tooltip": ""
     }
    },
    "5bfdc7d0fa2e4fb7ac8851bfccad007a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_0e22b5edf1714aff836c63358a42da9f",
      "style": "IPY_MODEL_e3b17c3a9395456082e1bc99e14423d0",
      "value": true
     }
    },
    "680004ad9e1a4f05b529c93e5bd56203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ca17f35a50e43ce9363334f56c50c1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cb45b34c40e4bea8c717b5164760aed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "a4734373175d4e66831f85faf5fb305d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [],
      "layout": "IPY_MODEL_2577091f2398431cb8fa3bb48c3c033c"
     }
    },
    "b4cf051c8f184fe3be3237818c9a17be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfdc20d4ca6c438fbabb1618b2f3a308": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c16d7495f7a74acdaef4ed386262d8d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c86cce7d6f804a93a7e41d746370cd16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d02f4c3846604c34af270eae28db3405": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3b17c3a9395456082e1bc99e14423d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffd233c3f19b42c182c4ba632881b6b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
